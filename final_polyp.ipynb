{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-15T04:01:35.379972Z","iopub.status.busy":"2023-11-15T04:01:35.379575Z","iopub.status.idle":"2023-11-15T04:01:35.386765Z","shell.execute_reply":"2023-11-15T04:01:35.385739Z","shell.execute_reply.started":"2023-11-15T04:01:35.379940Z"},"trusted":true},"outputs":[],"source":["import os\n","import pandas as pd\n","import numpy as np\n","import cv2\n","from torchvision.io import read_image\n","import matplotlib.pyplot as plt\n","from torch.utils.data import Dataset, random_split, DataLoader, ConcatDataset\n","import albumentations as A\n","from albumentations.pytorch.transforms import ToTensorV2\n","\n","from torchvision.transforms import ToTensor\n","from PIL import Image\n","import os\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision \n","from torchvision import transforms\n","from torchinfo import summary\n","import timm\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-15T04:01:35.553434Z","iopub.status.busy":"2023-11-15T04:01:35.553078Z","iopub.status.idle":"2023-11-15T04:01:36.529988Z","shell.execute_reply":"2023-11-15T04:01:36.528868Z","shell.execute_reply.started":"2023-11-15T04:01:35.553406Z"},"trusted":true},"outputs":[],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-15T04:01:36.533052Z","iopub.status.busy":"2023-11-15T04:01:36.532615Z","iopub.status.idle":"2023-11-15T04:01:36.548947Z","shell.execute_reply":"2023-11-15T04:01:36.547965Z","shell.execute_reply.started":"2023-11-15T04:01:36.533005Z"},"trusted":true},"outputs":[],"source":["class CustomImageDataset(Dataset):\n","    def __init__(self, img_dir, label_dir, resize=None, transform=None):\n","        self.img_dir = img_dir\n","        self.label_dir = label_dir\n","        self.resize = resize\n","        self.transform = transform\n","        self.images = os.listdir(self.img_dir)\n","\n","    def __len__(self):\n","        return len(self.images)\n","    def read_mask(self, mask_path):\n","        image = cv2.imread(mask_path)\n","        image = cv2.resize(image, self.resize)\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n","        # lower boundary RED color range values; Hue (0 - 10)\n","        lower1 = np.array([0, 100, 20])\n","        upper1 = np.array([10, 255, 255])\n","        # upper boundary RED color range values; Hue (160 - 180)\n","        lower2 = np.array([160,100,20])\n","        upper2 = np.array([179,255,255])\n","        lower_mask = cv2.inRange(image, lower1, upper1)\n","        upper_mask = cv2.inRange(image, lower2, upper2)\n","        \n","        red_mask = lower_mask + upper_mask;\n","        red_mask[red_mask != 0] = 1\n","\n","        # boundary GREEN color range values; Hue (36 - 70)\n","        green_mask = cv2.inRange(image, (36, 25, 25), (70, 255, 255))\n","        green_mask[green_mask != 0] = 2\n","\n","        full_mask = cv2.bitwise_or(red_mask, green_mask)\n","        full_mask = np.expand_dims(full_mask, axis=-1) \n","        full_mask = full_mask.astype(np.uint8)\n","        return full_mask\n","\n","    def __getitem__(self, idx):\n","        img_path = os.path.join(self.img_dir, self.images[idx])\n","        label_path = os.path.join(self.label_dir, self.images[idx])\n","        image = cv2.imread(img_path)  # Đọc ảnh dưới dạng BGR\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","        label = self.read_mask(label_path)  # Đọc nhãn dưới dạng BGR\n","        image = cv2.resize(image, self.resize)\n","        if self.transform:\n","            transformed = self.transform(image=image, mask=label)\n","            image = transformed['image']\n","            label = transformed['mask']\n","        return image, label\n","    def show_image(self, idx):\n","        img_path = os.path.join(self.img_dir, self.images[idx])\n","        label_path = os.path.join(self.label_dir, self.images[idx])\n","        image = plt.imread(img_path)\n","        label = plt.imread(label_path)\n","        fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n","        axs[0].imshow(image)\n","        axs[0].set_title('Image')\n","        axs[1].imshow(label)\n","        axs[1].set_title('Label')\n","        plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-15T04:01:36.550454Z","iopub.status.busy":"2023-11-15T04:01:36.550121Z","iopub.status.idle":"2023-11-15T04:01:36.859595Z","shell.execute_reply":"2023-11-15T04:01:36.858646Z","shell.execute_reply.started":"2023-11-15T04:01:36.550422Z"},"trusted":true},"outputs":[],"source":["image_path = []\n","TRAIN_DIR = '/kaggle/input/bkai-igh-neopolyp/train/train'\n","for root, dirs, files in os.walk(TRAIN_DIR):\n","    # iterate over 1000 images\n","    for file in files:\n","        # create path\n","        path = os.path.join(root,file)\n","        # add path to list\n","        image_path.append(path)\n","len(image_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-15T04:01:36.861786Z","iopub.status.busy":"2023-11-15T04:01:36.861506Z","iopub.status.idle":"2023-11-15T04:01:37.165624Z","shell.execute_reply":"2023-11-15T04:01:37.164720Z","shell.execute_reply.started":"2023-11-15T04:01:36.861762Z"},"trusted":true},"outputs":[],"source":["mask_path = []\n","TRAIN_MASK_DIR = '/kaggle/input/bkai-igh-neopolyp/train_gt/train_gt'\n","for root, dirs, files in os.walk(TRAIN_MASK_DIR):\n","    #iterate over 1000 masks\n","    for file in files:\n","        # obtain the path\"\n","        path = os.path.join(root,file)\n","        # add path to the list\n","        mask_path.append(path)\n","len(mask_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-15T04:01:37.167185Z","iopub.status.busy":"2023-11-15T04:01:37.166844Z","iopub.status.idle":"2023-11-15T04:01:37.172759Z","shell.execute_reply":"2023-11-15T04:01:37.171912Z","shell.execute_reply.started":"2023-11-15T04:01:37.167153Z"},"trusted":true},"outputs":[],"source":["trainsize = 384\n","batch_size = 8\n","\n","dataset = CustomImageDataset(img_dir= TRAIN_DIR,\n","                             label_dir= TRAIN_MASK_DIR,\n","                             resize= (trainsize,trainsize),\n","                             transform = None)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-15T04:01:37.174229Z","iopub.status.busy":"2023-11-15T04:01:37.173912Z","iopub.status.idle":"2023-11-15T04:01:37.201995Z","shell.execute_reply":"2023-11-15T04:01:37.201101Z","shell.execute_reply.started":"2023-11-15T04:01:37.174203Z"},"trusted":true},"outputs":[],"source":["total_size = len(dataset)\n","train_size = int(total_size * 0.9)\n","valid_size = total_size - train_size\n","\n","# Split the dataset\n","train_dataset, val_dataset = random_split(dataset, [train_size, valid_size])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-15T04:01:37.204990Z","iopub.status.busy":"2023-11-15T04:01:37.204668Z","iopub.status.idle":"2023-11-15T04:01:37.221262Z","shell.execute_reply":"2023-11-15T04:01:37.220396Z","shell.execute_reply.started":"2023-11-15T04:01:37.204965Z"},"trusted":true},"outputs":[],"source":["class CustomDataset(CustomImageDataset):\n","    def __init__(self, dataset, transform=None):\n","        self.dataset = dataset\n","        self.transform = transform\n","\n","    def __getitem__(self, index):\n","        image, label = self.dataset[index] \n","        if self.transform:\n","            transformed = self.transform(image=image, mask=label)\n","            image = transformed['image']\n","            label = transformed['mask']\n","            label = label.permute(2,0,1)\n","        return image, label\n","\n","    def __len__(self):\n","        return len(self.dataset)\n","\n","train_transform = A.Compose([\n","    A.HorizontalFlip(p=0.5),\n","    A.VerticalFlip(p=0.5),\n","    A.RandomGamma (gamma_limit=(70, 130), eps=None, always_apply=False, p=0.2),\n","    A.RGBShift(p=0.3, r_shift_limit=10, g_shift_limit=10, b_shift_limit=10),\n","    A.OneOf([A.Blur(), A.GaussianBlur(), A.GlassBlur(), A.MotionBlur(), A.GaussNoise(), A.Sharpen(), A.MedianBlur(), A.MultiplicativeNoise()]),\n","    A.Cutout(p=0.2, max_h_size=35, max_w_size=35, fill_value=255),\n","    A.RandomSnow(snow_point_lower=0.1, snow_point_upper=0.15, brightness_coeff=1.5, p=0.09),\n","    A.RandomShadow(p=0.1),\n","    A.ShiftScaleRotate(p=0.45, border_mode=cv2.BORDER_CONSTANT, shift_limit=0.15, scale_limit=0.15),\n","    A.RandomCrop(384, 384),\n","    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n","    ToTensorV2(),\n","])\n","\n","val_transform = A.Compose([\n","    A.Normalize(mean=(0.485, 0.456, 0.406),std=(0.229, 0.224, 0.225)),\n","    ToTensorV2(),\n","])\n","\n","train_dataset_not_aug = CustomDataset(train_dataset,\n","                             transform = val_transform)\n","train_dataset_aug = CustomDataset(train_dataset,\n","                             transform = train_transform)\n","val_dataset = CustomDataset(val_dataset,\n","                             transform = val_transform)\n","\n","train_dataset_new = ConcatDataset([train_dataset_not_aug, train_dataset_aug])\n","\n","train_loader = DataLoader(train_dataset_new, batch_size= batch_size, shuffle= True)\n","val_loader = DataLoader(val_dataset, batch_size= batch_size, shuffle= False)\n","print(len(train_dataset_new))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-15T04:01:37.224272Z","iopub.status.busy":"2023-11-15T04:01:37.223664Z","iopub.status.idle":"2023-11-15T04:01:37.701272Z","shell.execute_reply":"2023-11-15T04:01:37.700222Z","shell.execute_reply.started":"2023-11-15T04:01:37.224236Z"},"trusted":true},"outputs":[],"source":["image,label = train_dataset_new[0]\n","print('Image: ', image.shape, 'Label: ', label.shape)\n","\n","label_array = label.permute(1, 2, 0).numpy()\n","image_array = image.permute(1, 2, 0).numpy()\n","# Create a figure with 2 subplots (1 row, 2 columns)\n","fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n","\n","axs[0].imshow(image_array)\n","axs[0].set_title('Image')\n","axs[0].axis('off')  \n","\n","axs[1].imshow(label_array)\n","axs[1].set_title('Label')\n","axs[1].axis('off')  \n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-15T04:01:37.703315Z","iopub.status.busy":"2023-11-15T04:01:37.702956Z","iopub.status.idle":"2023-11-15T04:01:37.719538Z","shell.execute_reply":"2023-11-15T04:01:37.718448Z","shell.execute_reply.started":"2023-11-15T04:01:37.703283Z"},"trusted":true},"outputs":[],"source":["class DoubleConv(nn.Module):\n","    def __init__(self, in_channels, out_channels, bottle_neck = False):\n","        super(DoubleConv, self).__init__() \n","        self.double_conv = nn. Sequential(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1), \n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1), nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True)\n","        )\n","        if bottle_neck == True:\n","            self.double_conv = nn. Sequential(\n","                nn.Conv2d(in_channels, out_channels*2, kernel_size=3, padding=1), \n","                nn.BatchNorm2d(out_channels*2),\n","                nn.ReLU(inplace=True),\n","                nn.Conv2d(out_channels*2, out_channels, kernel_size=3, padding=1),\n","                nn.BatchNorm2d(out_channels),\n","                nn.ReLU(inplace=True)\n","        )\n","    def forward(self, x):\n","        return self.double_conv(x)\n","\n","class DownBlock (nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(DownBlock, self).__init__()\n","        self.double_conv = DoubleConv(in_channels, out_channels) \n","        self.down_sample = nn.MaxPool2d(2)\n","        \n","    def forward(self, x):\n","        skip_out = self.double_conv(x) \n","        down_out = self.down_sample(skip_out) \n","        return (down_out, skip_out)\n","class UpBlock (nn.Module):\n","    def __init__(self, in_channels, out_channels, up_sample_mode):\n","        super(UpBlock, self).__init__()\n","        if up_sample_mode == 'conv_transpose':\n","            if out_channels*4 == in_channels:\n","                self.up_sample= nn.ConvTranspose2d(in_channels-out_channels*2, in_channels-out_channels*2, kernel_size=2, stride=2)\n","            else:\n","                self.up_sample= nn.ConvTranspose2d(in_channels-out_channels, in_channels-out_channels, kernel_size=2, stride=2) \n","        else:\n","            self.up_sample= nn.Upsample (scale_factor=2, mode='bilinear', align_corners=True)\n","        self.double_conv = DoubleConv(in_channels, out_channels)\n","\n","    def forward(self, down_input, skip_input):\n","        x = self.up_sample(down_input)\n","        x = torch.cat([x, skip_input], dim=1) \n","        return self.double_conv(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-15T04:01:38.028623Z","iopub.status.busy":"2023-11-15T04:01:38.027896Z","iopub.status.idle":"2023-11-15T04:01:38.038752Z","shell.execute_reply":"2023-11-15T04:01:38.037766Z","shell.execute_reply.started":"2023-11-15T04:01:38.028592Z"},"trusted":true},"outputs":[],"source":["class PolypModel(nn.Module):\n","    def __init__(self, out_classes=3, up_sample_mode='conv_transpose'):\n","        super().__init__()\n","        self.out_classes = out_classes\n","        self.encoder = timm.create_model(\"resnet152\", pretrained=True, features_only=True)\n","#         self.down_conv1 = DownBlock(3, 64) \n","        self.down_conv1 = DownBlock(64, 128) \n","        self.down_conv2 = DownBlock(256, 512) \n","        self.down_conv3 = DownBlock (512, 1024) \n","        self.down_conv4 = DownBlock (1024, 2048) \n","        self.up_sample_mode = up_sample_mode\n","        self.block_neck = DoubleConv(2048, 1024)\n","        self.block_up1 = UpBlock (1024+1024, 512, self.up_sample_mode) \n","        self.block_up2 = UpBlock (512+512, 256, self.up_sample_mode) \n","        self.block_up3 = UpBlock (256+256, 128, self.up_sample_mode) \n","        self.block_up4 = UpBlock(128+64, 64, self.up_sample_mode) \n","        self.conv_last = nn.Conv2d(64, out_classes, kernel_size=1) \n","        self.upsample = nn.Upsample (scale_factor=2, mode=\"bilinear\")\n","    def forward(self, x):\n","        x1, x2, x3, x4, x5 = self.encoder(x)\n","        x = self.block_neck(x5)\n","        x = self.block_up1(x, x4)\n","        x = self.block_up2(x, x3)\n","        x = self.block_up3(x, x2) \n","        x = self.block_up4(x, x1)\n","        x = self.conv_last(x)\n","        x = self.upsample(x) \n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-15T04:01:38.567251Z","iopub.status.busy":"2023-11-15T04:01:38.566875Z","iopub.status.idle":"2023-11-15T04:01:38.574432Z","shell.execute_reply":"2023-11-15T04:01:38.573446Z","shell.execute_reply.started":"2023-11-15T04:01:38.567220Z"},"trusted":true},"outputs":[],"source":["color_dict= {0: (0, 0, 0),\n","             1: (255, 0, 0),\n","             2: (0, 255, 0)}\n","def mask_to_rgb(mask, color_dict):\n","    output = np.zeros((mask.shape[0], mask.shape[1], 3))\n","#     print(output.shape)\n","    for k in color_dict.keys():\n","        output[mask==k] = color_dict[k]\n","\n","    return np.uint8(output)    "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-15T04:01:39.484158Z","iopub.status.busy":"2023-11-15T04:01:39.483727Z","iopub.status.idle":"2023-11-15T04:01:43.424463Z","shell.execute_reply":"2023-11-15T04:01:43.423391Z","shell.execute_reply.started":"2023-11-15T04:01:39.484123Z"},"trusted":true},"outputs":[],"source":["torch.cuda.empty_cache()\n","model = PolypModel(3)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-15T04:01:43.426850Z","iopub.status.busy":"2023-11-15T04:01:43.426452Z","iopub.status.idle":"2023-11-15T04:01:43.435330Z","shell.execute_reply":"2023-11-15T04:01:43.434378Z","shell.execute_reply.started":"2023-11-15T04:01:43.426798Z"},"trusted":true},"outputs":[],"source":["# Define the optimizer (e.g., Adam optimizer)\n","learning_rate = 0.0001\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-14T17:42:12.371708Z","iopub.status.busy":"2023-11-14T17:42:12.371292Z","iopub.status.idle":"2023-11-14T17:42:28.121116Z","shell.execute_reply":"2023-11-14T17:42:28.119980Z","shell.execute_reply.started":"2023-11-14T17:42:12.371672Z"},"trusted":true},"outputs":[],"source":["!pip install wandb\n","!wandb login 'af3fff39f107c47a5441bad9ba81d9c46a34914b'"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-14T17:42:28.123060Z","iopub.status.busy":"2023-11-14T17:42:28.122750Z","iopub.status.idle":"2023-11-14T17:42:32.305466Z","shell.execute_reply":"2023-11-14T17:42:32.304491Z","shell.execute_reply.started":"2023-11-14T17:42:28.123032Z"},"trusted":true},"outputs":[],"source":["import wandb\n","wandb.login()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-14T17:42:32.307140Z","iopub.status.busy":"2023-11-14T17:42:32.306687Z","iopub.status.idle":"2023-11-14T17:43:05.482642Z","shell.execute_reply":"2023-11-14T17:43:05.481763Z","shell.execute_reply.started":"2023-11-14T17:42:32.307112Z"},"trusted":true},"outputs":[],"source":["wandb.init(\n","    project = 'Polyp',\n","    config = {\n","        'learning_rate': 0.0001,\n","        'architecture': 'Unet',\n","        'dataset': 'Polyp',\n","        'epoch': 200\n","    }\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-14T17:57:54.413666Z","iopub.status.busy":"2023-11-14T17:57:54.412833Z"},"trusted":true},"outputs":[],"source":["# Set the number of training epochs\n","num_epochs = 200\n","\n","# Move the model to the device (e.g., GPU)\n","device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","criterion = nn.CrossEntropyLoss()\n","train_loss_array = []\n","val_loss_array = []\n","best_val_loss = 999\n","# Training loop\n","for epoch in range(num_epochs):\n","    model.train()\n","    total_loss = 0\n","    for images, labels in train_loader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        # Forward pass\n","        labels = labels.squeeze(dim=1).long()\n","\n","        outputs = model(images)\n","\n","        loss = criterion(outputs, labels)\n","        \n","        # Backward pass and optimization\n","        loss.backward()\n","        optimizer.step()\n","        optimizer.zero_grad()\n","        total_loss += loss.item()  # Accumulate the loss\n","    train_loss_epoch = total_loss / len(train_loader)\n","\n","        \n","# Perform validation\n","    model.eval()\n","    with torch.no_grad():\n","        val_loss = 0\n","        for images, labels in val_loader:\n","            images = images.to(device)\n","            labels = labels.to(device)\n","            labels = labels.squeeze(dim=1).long()\n","\n","            # Forward pass\n","            outputs = model(images)\n","            val_loss += criterion(outputs.float(),labels.long()).item()\n","    val_loss_epoch = val_loss/len(val_loader)\n","    # Print the loss of valid_dataset for this epoch\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], val_loss: {val_loss/len(val_loader):.10f}\")\n","    if val_loss < best_val_loss:\n","        best_val_loss = val_loss\n","        checkpoint = { \n","            'model': model.state_dict(),\n","            'optimizer': optimizer.state_dict(),\n","        }\n","        save_path = f'colorization_model.pth'\n","        torch.save(checkpoint, save_path)\n","        print('SAVE +1')\n","    # Calculate average loss for the epoch\n","    \n","    wandb.log({'Val_loss': val_loss_epoch,\n","               'Train_loss': train_loss_epoch\n","              })\n","    train_loss_array.append(train_loss_epoch)\n","    val_loss_array.append(val_loss_epoch)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Plotting the training and validation loss\n","plt.figure(figsize=(10, 5))\n","plt.plot(train_loss_array, label='Training Loss')\n","plt.plot(val_loss_array, label='Validation Loss')\n","\n","# Adding title and labels\n","plt.title('Training and Validation Loss Per Epoch')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","\n","# Display the plot\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-15T04:46:48.658782Z","iopub.status.busy":"2023-11-15T04:46:48.658325Z","iopub.status.idle":"2023-11-15T04:46:48.663987Z","shell.execute_reply":"2023-11-15T04:46:48.663045Z","shell.execute_reply.started":"2023-11-15T04:46:48.658748Z"},"trusted":true},"outputs":[],"source":["checkpoint = torch.load('/kaggle/input/checkkpoint/checkpoint_final.pth')\n","model.load_state_dict(checkpoint['model'])\n","device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n","optimizer.load_state_dict(checkpoint['optimizer'])\n","model.to(device)\n","for state in optimizer.state.values():\n","    for k, v in state.items():\n","        if isinstance(v, torch.Tensor):\n","            state[k] = v.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-15T04:43:47.563394Z","iopub.status.busy":"2023-11-15T04:43:47.562974Z","iopub.status.idle":"2023-11-15T04:43:48.556907Z","shell.execute_reply":"2023-11-15T04:43:48.555618Z","shell.execute_reply.started":"2023-11-15T04:43:47.563361Z"},"trusted":true},"outputs":[],"source":["!mkdir predicted_mask"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-15T04:43:48.560479Z","iopub.status.busy":"2023-11-15T04:43:48.560070Z","iopub.status.idle":"2023-11-15T04:44:15.563872Z","shell.execute_reply":"2023-11-15T04:44:15.562930Z","shell.execute_reply.started":"2023-11-15T04:43:48.560439Z"},"trusted":true},"outputs":[],"source":["model.eval()\n","for i in os.listdir(\"/kaggle/input/bkai-igh-neopolyp/test/test\"):\n","    img_path = os.path.join(\"/kaggle/input/bkai-igh-neopolyp/test/test\", i)\n","    ori_img = cv2.imread(img_path)\n","    ori_img = cv2.cvtColor(ori_img, cv2.COLOR_BGR2RGB)\n","    ori_w = ori_img.shape[0]\n","    ori_h = ori_img.shape[1]\n","    img = cv2.resize(ori_img, (trainsize, trainsize))\n","    transformed = val_transform(image=img)\n","    input_img = transformed[\"image\"]\n","    input_img = input_img.unsqueeze(0).to(device)\n","    with torch.no_grad():\n","        output_mask = model.forward(input_img).squeeze(0).cpu().numpy().transpose(1,2,0)\n","    mask = cv2.resize(output_mask, (ori_h, ori_w))\n","    mask = np.argmax(mask, axis=2)\n","    mask_rgb = mask_to_rgb(mask, color_dict)\n","    mask_rgb = cv2.cvtColor(mask_rgb, cv2.COLOR_RGB2BGR)\n","    cv2.imwrite(\"predicted_mask/{}\".format(i), mask_rgb)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-15T04:44:15.565625Z","iopub.status.busy":"2023-11-15T04:44:15.565242Z","iopub.status.idle":"2023-11-15T04:44:18.419589Z","shell.execute_reply":"2023-11-15T04:44:18.418549Z","shell.execute_reply.started":"2023-11-15T04:44:15.565592Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import cv2\n","import os\n","\n","def rle_to_string(runs):\n","    return ' '.join(str(x) for x in runs)\n","\n","def rle_encode_one_mask(mask):\n","    pixels = mask.flatten()\n","    pixels[pixels > 225] = 255\n","    pixels[pixels <= 225] = 0\n","    use_padding = False\n","    if pixels[0] or pixels[-1]:\n","        use_padding = True\n","        pixel_padded = np.zeros([len(pixels) + 2], dtype=pixels.dtype)\n","        pixel_padded[1:-1] = pixels\n","        pixels = pixel_padded\n","    \n","    rle = np.where(pixels[1:] != pixels[:-1])[0] + 2\n","    if use_padding:\n","        rle = rle - 1\n","    rle[1::2] = rle[1::2] - rle[:-1:2]\n","    return rle_to_string(rle)\n","\n","def rle2mask(mask_rle, shape=(3,3)):\n","    '''\n","    mask_rle: run-length as string formated (start length)\n","    shape: (width,height) of array to return \n","    Returns numpy array, 1 - mask, 0 - background\n","\n","    '''\n","    s = mask_rle.split()\n","    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n","    starts -= 1\n","    ends = starts + lengths\n","    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n","    for lo, hi in zip(starts, ends):\n","        img[lo:hi] = 1\n","    return img.reshape(shape).T\n","\n","def mask2string(dir):\n","    ## mask --> string\n","    strings = []\n","    ids = []\n","    ws, hs = [[] for i in range(2)]\n","    for image_id in os.listdir(dir):\n","        id = image_id.split('.')[0]\n","        path = os.path.join(dir, image_id)\n","        print(path)\n","        img = cv2.imread(path)[:,:,::-1]\n","        h, w = img.shape[0], img.shape[1]\n","        for channel in range(2):\n","            ws.append(w)\n","            hs.append(h)\n","            ids.append(f'{id}_{channel}')\n","            string = rle_encode_one_mask(img[:,:,channel])\n","            strings.append(string)\n","    r = {\n","        'ids': ids,\n","        'strings': strings,\n","    }\n","    return r\n","\n","\n","MASK_DIR_PATH = '/kaggle/working/predicted_mask' # change this to the path to your output mask folder\n","dir = MASK_DIR_PATH\n","res = mask2string(dir)\n","df = pd.DataFrame(columns=['Id', 'Expected'])\n","df['Id'] = res['ids']\n","df['Expected'] = res['strings']\n","\n","df.to_csv(r'output.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":2715462,"sourceId":30892,"sourceType":"competition"},{"datasetId":4004924,"sourceId":6970550,"sourceType":"datasetVersion"},{"datasetId":4005006,"sourceId":6970716,"sourceType":"datasetVersion"}],"dockerImageVersionId":30559,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
